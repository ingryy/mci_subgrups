{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA2 -  Random Frorests - baseline\n",
    "\n",
    "## Features w/renaming:\n",
    "1. 'AGE' -> age\n",
    "1. 'PTGENDER (Gender_)' -> Geder\n",
    "1. 'RAVLT_immediate', -> RAVLT immediate\n",
    "1. 'AVDEL30MIN_neuro' -> RAVLT delayed \n",
    "1. 'AVDELTOT_neuro', -> RAVLT recognition \n",
    "1. 'TRAASCOR_neuro', -> Trail Making A\n",
    "1. 'TRABSCOR_neuro', -> Trail Making B\n",
    "1. 'CATANIMSC_neuro' -> Category Fluency \n",
    "1. 'GDTOTAL_gds' -> GDS \n",
    "1. 'ANART' -> ANART\n",
    "1. 'Apoe4' -> Apoe 4 \n",
    "1. 'LRHHC_n_long' -> Hippocampus\n",
    "\n",
    "---\n",
    "\n",
    "**Resources**\n",
    "1. DATA\n",
    "    1. [data/data2](https://github.com/MMIV-ML/MCI-subgroups/tree/master/data/data2) - csv files downloaded from ADNI,\n",
    "    1. [data/data2_FS](https://github.com/MMIV-ML/MCI-subgroups/tree/master/data/data2_FS) - FS result csv files,\n",
    "    1. [data_zip/20201109_data2_file_versions](https://github.com/MMIV-ML/MCI-subgroups/blob/master/data/data_zip/20201109_data2_file_versions.pdf) - download ADNI web page screen shoot taken for downaloaded csv files (some of file neames are printed with dates),\n",
    "1. RESULTS\n",
    "    1. [results/20210420](https://github.com/MMIV-ML/MCI-subgroups/tree/master/results/20210420) - result folder,\n",
    "    1. [results/202100420/README.md](https://github.com/MMIV-ML/MCI-subgroups/blob/master/results/20210420/README.md) - short description,\n",
    "1. GOOGLE DRIVE\n",
    "    1. [slides](https://docs.google.com/presentation/d/1aEK7M5BPe0RxWYskzQCEDbT4Mf-4mRRqQ5uJ_YuqRzg/edit#slide=id.p) - link to google slides (**OUT OF DATE, MUST BE UPDATED !!!**),\n",
    "    1. [GoogleDrive](https://drive.google.com/drive/folders/1r8l2R88-0T8Xahk30iAgjBCWXvV1R2J-) - the main google drive slide folder,\n",
    "1. GIT HUB\n",
    "    1. [GitHub](https://github.com/MMIV-ML/MCI-subgroups) - the main repo folder,\n",
    "1. MODEL ACCURACY COMPARISION\n",
    "    1. [overview](https://github.com/MMIV-ML/MCI-subgroups/blob/master/results/20210420/3.xx_RF_bl_comparison.pdf) - to update!\n",
    "\n",
    "The latest changes (ver. 0.10):\n",
    "\n",
    "    -\n",
    "    \n",
    "   *Created: 2021.03.18 / Updated: 2021.04.30*\n",
    "   \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mci_info as minfo\n",
    "import mci_utils as mutils\n",
    "import mci_freesurfer as mfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook folder\n",
    "NB_DIR = %pwd\n",
    "NB_DIR = Path(NB_DIR)\n",
    "# Root MCI foler\n",
    "ROOT_DIR = NB_DIR.parent\n",
    "# Main data folder (with downloaded csv files)\n",
    "MAIN_DATA_DIR = ROOT_DIR/'data/data2'\n",
    "DATA_DIR_FS = ROOT_DIR / 'data/data2_FS'\n",
    "# Current data dir with sMCI_cAD.csv & bl.csv files\n",
    "CURRENT_DATA_DIR = ROOT_DIR/'results/20201110'\n",
    "# Results folder\n",
    "RESULTS_DIR = ROOT_DIR/'results/20210420' #misclassified patient table\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTALLED PACKAGES INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Computer name: Ingrids-MacBook-Air-3.local\n",
      "Operating system: Darwin, 64bit\n",
      "\n",
      "Python path: /Users/ingridrye/opt/miniconda3/envs/mci/bin/python\n",
      "Python version: 3.7.10 (default, Feb 26 2021, 10:16:00) \n",
      "[Clang 10.0.0 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>module</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eli5</td>\n",
       "      <td>0.11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ipywidgets</td>\n",
       "      <td>7.6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>matplotlib</td>\n",
       "      <td>3.3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>numpy</td>\n",
       "      <td>1.20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pandas</td>\n",
       "      <td>1.2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pdpbox</td>\n",
       "      <td>0.2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>scipy</td>\n",
       "      <td>1.6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>seaborn</td>\n",
       "      <td>0.11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>statsmodels</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         module version\n",
       "4          eli5  0.11.0\n",
       "6    ipywidgets   7.6.3\n",
       "10   matplotlib   3.3.4\n",
       "12        numpy  1.20.1\n",
       "14       pandas   1.2.4\n",
       "15       pdpbox   0.2.1\n",
       "19        scipy   1.6.2\n",
       "20      seaborn  0.11.1\n",
       "23  statsmodels        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 1:\n",
    "    packages = ['numpy', 'scipy', 'seaborn', 'pandas', 'matplotlib', 'statsmodels', 'ipywidgets', 'eli5', 'pdpbox']\n",
    "    display(mutils.package_versions(installedOnly=False, theMostImportant=packages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET FILE DESCRIPTIVE VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['AGE', 'Gender_', 'RAVLT_immediate', 'AVDEL30MIN_neuro', 'AVDELTOT_neuro', 'TRAASCOR_neuro', 'TRABSCOR_neuro',\n",
    "            'CATANIMSC_neuro','GDTOTAL_gds', 'ANARTERR_neuro', 'LRHHC_n_long', 'Apoe4_', 'Subgroup_']\n",
    "\n",
    "file_name_prefix = '3.16-feats'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD BASE LINE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects: \t708\n"
     ]
    }
   ],
   "source": [
    "bl_name = CURRENT_DATA_DIR / 'bl.csv'\n",
    "bl_all = pd.read_csv(bl_name, index_col=0)\n",
    "\n",
    "print(f'Subjects: \\t{bl_all.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERTS STRING LABESLS TO INTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male      425\n",
      "Female    283\n",
      "Name: PTGENDER, dtype: int64\n",
      "0    425\n",
      "1    283\n",
      "Name: Gender_, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#y_train_b = y_train.map({'cAD': 1, 'sMCI': 0}).astype(int)\n",
    "bl_all['Gender_'] = bl_all['PTGENDER'].map({'Female':1, 'Male':0})\n",
    "print(bl_all.PTGENDER.value_counts())\n",
    "print(bl_all.Gender_.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AGE                          0\n",
       "Gender_                      0\n",
       "RAVLT_immediate              0\n",
       "AVDEL30MIN_neuro             0\n",
       "AVDELTOT_neuro               1\n",
       "TRAASCOR_neuro               0\n",
       "TRABSCOR_neuro              10\n",
       "CATANIMSC_neuro              0\n",
       "GDTOTAL_gds                  0\n",
       "ANARTERR_neuro               6\n",
       "LRHHC_n_long                14\n",
       "Apoe4_                       0\n",
       "Subgroup_                    0\n",
       "Usage_                       0\n",
       "Subgroup_                    0\n",
       "Participation_length_yr_     0\n",
       "PTEDUCAT                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features2 = features + ['Usage_', 'Subgroup_', 'Participation_length_yr_', 'PTEDUCAT']\n",
    "bl_xxx = bl_all[features2]\n",
    "print(bl_xxx.shape)\n",
    "bl_xxx.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SELECT TRAIN SUBSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_train = bl_all.loc[bl_all.Usage_ == 'train']\n",
    "bl_test = bl_all.loc[bl_all.Usage_ == 'test']\n",
    "\n",
    "# backup of oryignal train data\n",
    "bl_train_all_copy = bl_train.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects:\n",
      "\t- train: 566 (80%)\n",
      "\t- test: 142 (20%)\n",
      "\n",
      "Subgroup count:\n",
      "\n",
      "*** Train set ***\n",
      "sMCI    305\n",
      "cAD     261\n",
      "Name: Subgroup_, dtype: int64\n",
      "\n",
      "*** Test set ***\n",
      "sMCI    76\n",
      "cAD     66\n",
      "Name: Subgroup_, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    bl_tr_ln = bl_train.shape[0]\n",
    "    bl_te_ln = bl_test.shape[0]\n",
    "    bl_ln = bl_all.shape[0]\n",
    "\n",
    "    print(f'Subjects:\\n\\t- train: {bl_tr_ln} ({bl_tr_ln / bl_ln *100:.0f}%)\\n\\t- test: {bl_te_ln} ({bl_te_ln / bl_ln *100 :.0f}%)\\n')\n",
    "\n",
    "    print('Subgroup count:\\n')\n",
    "    print('*** Train set ***')\n",
    "    print(bl_train.Subgroup_.value_counts(dropna=False))\n",
    "    print('\\n*** Test set ***')\n",
    "    print(bl_test.Subgroup_.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDENTIFY COLUMN NAMES PRESENTED IN THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of columns: 105\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adni (#30)</th>\n",
       "      <th>adas (#16)</th>\n",
       "      <th>neuro (#14)</th>\n",
       "      <th>gds (#5)</th>\n",
       "      <th>ours (#20)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABETA</td>\n",
       "      <td>MERGE_long_adas</td>\n",
       "      <td>ANARTERR_neuro</td>\n",
       "      <td>EXAMDATE_gds</td>\n",
       "      <td>ADAS13_adni_Nr_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADAS13_adni</td>\n",
       "      <td>Q10_adas</td>\n",
       "      <td>AVDEL30MIN_neuro</td>\n",
       "      <td>GDTOTAL_gds</td>\n",
       "      <td>Abeta_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGE</td>\n",
       "      <td>Q11_adas</td>\n",
       "      <td>AVDELTOT_neuro</td>\n",
       "      <td>MERGE_long_gds</td>\n",
       "      <td>Age_at_scan_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APOE4</td>\n",
       "      <td>Q12_adas</td>\n",
       "      <td>AVTOT6_neuro</td>\n",
       "      <td>Phase_gds</td>\n",
       "      <td>Age_at_scan_rounded_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CDRSB</td>\n",
       "      <td>Q13_adas</td>\n",
       "      <td>AVTOTB_neuro</td>\n",
       "      <td>VISCODE2_gds</td>\n",
       "      <td>Age_bin_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DX</td>\n",
       "      <td>Q1_adas</td>\n",
       "      <td>CATANIMSC_neuro</td>\n",
       "      <td></td>\n",
       "      <td>Age_rounded_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DX_bl</td>\n",
       "      <td>Q2_adas</td>\n",
       "      <td>CLOCKSCOR_neuro</td>\n",
       "      <td></td>\n",
       "      <td>Apoe4_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXAMDATE</td>\n",
       "      <td>Q3_adas</td>\n",
       "      <td>COPYSCOR_neuro</td>\n",
       "      <td></td>\n",
       "      <td>Gender_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FAQ</td>\n",
       "      <td>Q4_adas</td>\n",
       "      <td>EXAMDATE_neuro</td>\n",
       "      <td></td>\n",
       "      <td>Gender_num_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IMAGEUID</td>\n",
       "      <td>Q5_adas</td>\n",
       "      <td>MERGE_long_neuro</td>\n",
       "      <td></td>\n",
       "      <td>Idx_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LDELTOTAL</td>\n",
       "      <td>Q6_adas</td>\n",
       "      <td>Phase_neuro</td>\n",
       "      <td></td>\n",
       "      <td>Imageuid_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MMSE</td>\n",
       "      <td>Q7_adas</td>\n",
       "      <td>TRAASCOR_neuro</td>\n",
       "      <td></td>\n",
       "      <td>MERGE_FS_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Month</td>\n",
       "      <td>Q8_adas</td>\n",
       "      <td>TRABSCOR_neuro</td>\n",
       "      <td></td>\n",
       "      <td>MRIs_Nr_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Month_bl</td>\n",
       "      <td>Q9_adas</td>\n",
       "      <td>VISCODE2_neuro</td>\n",
       "      <td></td>\n",
       "      <td>Participation_length_yr_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ORIGPROT</td>\n",
       "      <td>TOTAL13_adas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Subgroup_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PTAU</td>\n",
       "      <td>VISCODE3_adas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Subgroup_num_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PTEDUCAT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>TOTAL13_adas_Nr_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PTETHCAT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Usage_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PTGENDER</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>VISCODE3_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PTID</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Visits_Nr_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PTRACCAT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Phase</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RAVLT_forgetting</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RAVLT_immediate</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RAVLT_learning</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RAVLT_perc_forgetting</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RID</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TAU</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TRABSCOR_adni</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Years_bl</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               adni (#30)       adas (#16)       neuro (#14)        gds (#5)  \\\n",
       "0                   ABETA  MERGE_long_adas    ANARTERR_neuro    EXAMDATE_gds   \n",
       "1             ADAS13_adni         Q10_adas  AVDEL30MIN_neuro     GDTOTAL_gds   \n",
       "2                     AGE         Q11_adas    AVDELTOT_neuro  MERGE_long_gds   \n",
       "3                   APOE4         Q12_adas      AVTOT6_neuro       Phase_gds   \n",
       "4                   CDRSB         Q13_adas      AVTOTB_neuro    VISCODE2_gds   \n",
       "5                      DX          Q1_adas   CATANIMSC_neuro                   \n",
       "6                   DX_bl          Q2_adas   CLOCKSCOR_neuro                   \n",
       "7                EXAMDATE          Q3_adas    COPYSCOR_neuro                   \n",
       "8                     FAQ          Q4_adas    EXAMDATE_neuro                   \n",
       "9                IMAGEUID          Q5_adas  MERGE_long_neuro                   \n",
       "10              LDELTOTAL          Q6_adas       Phase_neuro                   \n",
       "11                   MMSE          Q7_adas    TRAASCOR_neuro                   \n",
       "12                  Month          Q8_adas    TRABSCOR_neuro                   \n",
       "13               Month_bl          Q9_adas    VISCODE2_neuro                   \n",
       "14               ORIGPROT     TOTAL13_adas                                     \n",
       "15                   PTAU    VISCODE3_adas                                     \n",
       "16               PTEDUCAT                                                      \n",
       "17               PTETHCAT                                                      \n",
       "18               PTGENDER                                                      \n",
       "19                   PTID                                                      \n",
       "20               PTRACCAT                                                      \n",
       "21                  Phase                                                      \n",
       "22       RAVLT_forgetting                                                      \n",
       "23        RAVLT_immediate                                                      \n",
       "24         RAVLT_learning                                                      \n",
       "25  RAVLT_perc_forgetting                                                      \n",
       "26                    RID                                                      \n",
       "27                    TAU                                                      \n",
       "28          TRABSCOR_adni                                                      \n",
       "29               Years_bl                                                      \n",
       "\n",
       "                  ours (#20)  \n",
       "0            ADAS13_adni_Nr_  \n",
       "1                     Abeta_  \n",
       "2               Age_at_scan_  \n",
       "3       Age_at_scan_rounded_  \n",
       "4                   Age_bin_  \n",
       "5               Age_rounded_  \n",
       "6                     Apoe4_  \n",
       "7                    Gender_  \n",
       "8                Gender_num_  \n",
       "9                       Idx_  \n",
       "10                 Imageuid_  \n",
       "11                 MERGE_FS_  \n",
       "12                  MRIs_Nr_  \n",
       "13  Participation_length_yr_  \n",
       "14                 Subgroup_  \n",
       "15             Subgroup_num_  \n",
       "16          TOTAL13_adas_Nr_  \n",
       "17                    Usage_  \n",
       "18                 VISCODE3_  \n",
       "19                Visits_Nr_  \n",
       "20                            \n",
       "21                            \n",
       "22                            \n",
       "23                            \n",
       "24                            \n",
       "25                            \n",
       "26                            \n",
       "27                            \n",
       "28                            \n",
       "29                            "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minfo.included_feature_info(bl_train, pattern='adni-adas-neuro-gds-_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELECT SUBSET OF COLUMNS TO TRAIN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_train = bl_train[features]\n",
    "bl_test = bl_test[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE COLLUMN NAMES ???\n",
    "\n",
    "# REMEMBER TO MAKE CODE CELL INSTEAD OF MARKDOWN. NEED TO ASK MAREK HOW TO GET THESE NAMES ALSO FOR PDP-PLOTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_train = bl_train.rename({'AGE':'Age',\n",
    "                             'Gender_': 'Gender',\n",
    "                             'RAVLT_immediate' : 'RAVLT immediate',\n",
    "                             'AVDEL30MIN_neuro': 'RAVLT delayed',\n",
    "                             'AVDELTOT_neuro': 'RAVLT recognition',\n",
    "                             'TRAASCOR_neuro' : 'Trail Making A',\n",
    "                             'TRABSCOR_neuro': 'Trail Making B',\n",
    "                             'CATANIMSC_neuro': 'Category Fluency',\n",
    "                             'GDTOTAL_gds': 'GDS',\n",
    "                             'ANARTERR_neuro': 'ANART',\n",
    "                             'Apoe4_' : 'Apoe 4',\n",
    "                             'LRHHC_n_long': 'Hippocampus'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_test = bl_test.rename({'AGE':'Age',\n",
    "                             'Gender_': 'Gender',\n",
    "                             'RAVLT_immediate' : 'RAVLT immediate',\n",
    "                             'AVDEL30MIN_neuro': 'RAVLT delayed',\n",
    "                             'AVDELTOT_neuro': 'RAVLT recognition',\n",
    "                             'TRAASCOR_neuro' : 'Trail Making A',\n",
    "                             'TRABSCOR_neuro': 'Trail Making B',\n",
    "                             'CATANIMSC_neuro': 'Category Fluency',\n",
    "                             'GDTOTAL_gds': 'GDS',\n",
    "                             'ANARTERR_neuro': 'ANART',\n",
    "                             'Apoe4_' : 'Apoe 4',\n",
    "                             'LRHHC_n_long': 'Hippocampus'}, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COUNT NAN VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** NaN values in TRAIN set ***\n",
      "(566, 13)\n",
      "Age                   0\n",
      "Gender                0\n",
      "RAVLT immediate       0\n",
      "RAVLT delayed         0\n",
      "RAVLT recognition     1\n",
      "Trail Making A        0\n",
      "Trail Making B       10\n",
      "Category Fluency      0\n",
      "GDS                   0\n",
      "ANART                 4\n",
      "Hippocampus          13\n",
      "Apoe 4                0\n",
      "Subgroup_             0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      " *** NaN values in TEST set ***\n",
      "(142, 13)\n",
      "Age                  0\n",
      "Gender               0\n",
      "RAVLT immediate      0\n",
      "RAVLT delayed        0\n",
      "RAVLT recognition    0\n",
      "Trail Making A       0\n",
      "Trail Making B       0\n",
      "Category Fluency     0\n",
      "GDS                  0\n",
      "ANART                2\n",
      "Hippocampus          1\n",
      "Apoe 4               0\n",
      "Subgroup_            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    print(' *** NaN values in TRAIN set ***' )\n",
    "    print(bl_train.shape)\n",
    "    print(bl_train.isnull().sum())\n",
    "    \n",
    "    print('\\n\\n *** NaN values in TEST set ***' )\n",
    "    print(bl_test.shape)\n",
    "    print(bl_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REMOVE NAN VALUES\n",
    "\n",
    "\n",
    "Remove those 11 rows from `bl_train` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(539, 13)\n",
      "(139, 13)\n"
     ]
    }
   ],
   "source": [
    "bl_train = bl_train.dropna(axis='rows')\n",
    "print(bl_train.shape)\n",
    "bl_test = bl_test.dropna(axis='rows')\n",
    "print(bl_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** NaN values in TRAIN set ***\n",
      "(539, 13)\n",
      "Age                  0\n",
      "Gender               0\n",
      "RAVLT immediate      0\n",
      "RAVLT delayed        0\n",
      "RAVLT recognition    0\n",
      "Trail Making A       0\n",
      "Trail Making B       0\n",
      "Category Fluency     0\n",
      "GDS                  0\n",
      "ANART                0\n",
      "Hippocampus          0\n",
      "Apoe 4               0\n",
      "Subgroup_            0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      " *** NaN values in TEST set ***\n",
      "(139, 13)\n",
      "Age                  0\n",
      "Gender               0\n",
      "RAVLT immediate      0\n",
      "RAVLT delayed        0\n",
      "RAVLT recognition    0\n",
      "Trail Making A       0\n",
      "Trail Making B       0\n",
      "Category Fluency     0\n",
      "GDS                  0\n",
      "ANART                0\n",
      "Hippocampus          0\n",
      "Apoe 4               0\n",
      "Subgroup_            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    print(' *** NaN values in TRAIN set ***' )\n",
    "    print(bl_train.shape)\n",
    "    print(bl_train.isnull().sum())\n",
    "    \n",
    "    print('\\n\\n *** NaN values in TEST set ***' )\n",
    "    print(bl_test.shape)\n",
    "    print(bl_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FORESTS CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE X AND y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split between `train` and `test` data is done in the ([2.11-data-balance](./2.11-data2-data-balance.ipynb)) notebook. To get chunk of data for traingin we use a 'train' flag in the `Usage_` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "X_train = bl_train.copy(deep=True)\n",
    "y_train = X_train.Subgroup_\n",
    "\n",
    "# test set\n",
    "X_test = bl_test.copy(deep=True)\n",
    "y_test = X_test.Subgroup_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REMOVE THE TARGET (`SUBGROUP_`) COLUMN FROM THE TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Subgroup_\" column in train set:\tFalse\n",
      "\"Subgroup_\" columm in test set: \tFalse\n"
     ]
    }
   ],
   "source": [
    "if 'Subgroup_' in X_train.columns:\n",
    "    X_train = X_train.drop(columns='Subgroup_')\n",
    "if 'Subgroup_' in X_test.columns:\n",
    "    X_test = X_test.drop(columns='Subgroup_')\n",
    "\n",
    "print(f'\"Subgroup_\" column in train set:\\t{\"Subgroup_\" in X_train.columns}')\n",
    "print(f'\"Subgroup_\" columm in test set: \\t{\"Subgroup_\" in X_test.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(539, 12) (539,)\n",
      "(139, 12) (139,)\n"
     ]
    }
   ],
   "source": [
    "# print size of train / test sets\n",
    "if 1:\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID SEARCH (ONLY IF NEEDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run gridsearch (if grid_search=1) and save the model to a file\n",
    "# Load the best model from the file (if grid_search = 0)\n",
    "grid_search = 0\n",
    "\n",
    "# A filename of the the whole ridsearch structure\n",
    "file_name_prefix_ext = file_name_prefix + '.pkl'\n",
    "file_name_prefix_path = RESULTS_DIR / file_name_prefix_ext\n",
    "\n",
    "# define a stratification sheme\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "if grid_search:       \n",
    "    print(\"Searching the best RF's parameters...\")\n",
    "    pipe = make_pipeline(StandardScaler(),RandomForestClassifier(random_state=42))\n",
    "    #sorted(pipe.get_params().keys())\n",
    "\n",
    "    params = {\"randomforestclassifier__n_estimators\": [470, 480, 490],\n",
    "              \"randomforestclassifier__max_depth\": [3, 4, 5],\n",
    "              \"randomforestclassifier__max_features\": [3, 4, 5],\n",
    "              \"randomforestclassifier__min_samples_split\": [1, 2, 3],\n",
    "              \"randomforestclassifier__min_samples_leaf\": [1, 2, 3],\n",
    "              \"randomforestclassifier__bootstrap\": [True, False],\n",
    "              \"randomforestclassifier__criterion\": [\"gini\", \"entropy\"]}\n",
    "    \n",
    "    #params = {\"randomforestclassifier__n_estimators\": [373, 374, 375]}\n",
    "    \n",
    "    grid = GridSearchCV(estimator=pipe, param_grid=params, verbose=1, refit=True, cv=skf, n_jobs=-1)\n",
    "    # fit the best estimator to the train data\n",
    "    grid.fit(X_train, y_train)\n",
    "    # save best estimator to the file\n",
    "    joblib.dump(grid, file_name_prefix_path)     \n",
    "else:\n",
    "    print(\"Loading RF from a file...\")\n",
    "    grid = joblib.load(file_name_prefix_path)     \n",
    "\n",
    "    \n",
    "clf = grid.best_estimator_\n",
    "\n",
    "print()\n",
    "print(f'Best score: {grid.best_score_:.3f}\\n')\n",
    "print(f'Best params:')\n",
    "for k,v in grid.best_params_.items():\n",
    "    print(f'\\t{k}: {v}')\n",
    "#print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A PIPELINE WITH ESTABLISHED RF PARAMETERS (WITHOUTH GRID SEARCH) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE STANDARIZATION IN THE TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarization - standar scaler from scikit-learn\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_train_scaled.set_index(X_train.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERWRITE \n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_scaled = X_train\n",
    "X_test_scaled = X_test\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_train_scaled.set_index(X_train.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TABLE CONTENT CHECKING (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:    \n",
    "    tmp_df = pd.DataFrame.from_dict({'X_train_mean':X_train.mean().round(2), 'X_train_std':X_train.std().round(2), \n",
    "                        'X_train_scaled_mean':X_train_scaled.mean().round(2), 'X_train_scaled_std':X_train_scaled.std().round(2)})\n",
    "    \n",
    "    display(X_train.head())\n",
    "    display(X_train_scaled.head())\n",
    "    display(tmp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LABEL FEATURE MAPPING FROM STRING TO FINITE INT VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** Train set ***')\n",
    "y_train_b = y_train.map({'cAD': 1, 'sMCI': 0}).astype(int)\n",
    "print(y_train_b.value_counts())\n",
    "print('\\n*** Test set ***')\n",
    "y_test_b = y_test.map({'cAD': 1, 'sMCI': 0}).astype(int)\n",
    "print(y_test_b.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF MODEL WITH CV (10 FOLDS)\n",
    "\n",
    "Hyperparameters optimized May 3rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 10\n",
    "\n",
    "#cls_save_name = 'cog_6_features'\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle=False)\n",
    "clf = RandomForestClassifier(random_state=0,\n",
    "                             n_estimators=480,\n",
    "                             max_depth=4,\n",
    "                             bootstrap=True,\n",
    "                             criterion='gini',\n",
    "                             min_samples_split=2,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features=4\n",
    "                            )\n",
    "\n",
    "# auxiliary structures (dfs, matrices) \n",
    "score = pd.DataFrame(index=[ 'f1_', 'acc_', 'recall_', 'prec_'], columns=list(range(folds)))\n",
    "feat_importance_all = pd.DataFrame(index=X_train_scaled.columns, columns=list(range(folds)))\n",
    "conf_matrix_all = np.zeros((folds, 2 ,2))\n",
    "df_err_predictions = pd.DataFrame()\n",
    "# to calculate mean validation test lenght, as it is 55 or 56\n",
    "validation_test_length = np.ones(10)\n",
    "\n",
    "\n",
    "\n",
    "for k, (train_index, validation_index) in enumerate(skf.split(X_train_scaled, y_train_b)):\n",
    "    #print(\"TRAIN:\", train_index.shape, \"VAL:\", test_index.shape)\n",
    "    X_train, X_validation = X_train_scaled.iloc[train_index,:], X_train_scaled.iloc[validation_index,:]\n",
    "    y_train, y_validation = y_train_b.iloc[train_index], y_train_b.iloc[validation_index]\n",
    "         \n",
    "    # model fit\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = clf.predict(X_validation).reshape(-1,)\n",
    "    \n",
    "    # metrics\n",
    "    f1 = metrics.f1_score(y_validation, y_pred)\n",
    "    acc = metrics.accuracy_score(y_validation, y_pred)\n",
    "    recall = metrics.recall_score(y_validation, y_pred)\n",
    "    prec = metrics.precision_score(y_validation, y_pred)\n",
    "    score[k] = [f1, acc, recall, prec]\n",
    "    \n",
    "    conf_matrix_all[k, :, :]  = metrics.confusion_matrix(y_validation, y_pred)    \n",
    "    feat_importance_all[k] = clf.feature_importances_\n",
    "    \n",
    "    \n",
    "    # add predictions and misclassifications to the training set\n",
    "    X_validation_extended = X_validation.copy()\n",
    "    X_validation_extended['y_true_'] = np.where(y_validation == 1, 'cAD', 'sMCI')\n",
    "    X_validation_extended['y_pred_'] = np.where(y_pred == 1, 'cAD', 'sMCI')\n",
    "    X_validation_extended['KFolds_nr_'] = f'k{folds}'\n",
    "    X_validation_extended['Fold_nr_'] = k\n",
    "    X_validation_extended['Usage2_'] = 'valid'\n",
    "    \n",
    "    # set current validation test set length\n",
    "    validation_test_length[k] = len(y_validation)\n",
    "    \n",
    "    # df with misclasified subjects for the current fold\n",
    "    err = X_validation_extended.loc[(X_validation_extended.y_true_ != X_validation_extended.y_pred_)]\n",
    "    print(f'fold: {k}, errors: {err.shape[0]}/{y_validation.shape[0]}  ({err.shape[0]/y_validation.shape[0]*100 :.1f}%)')\n",
    "    \n",
    "    # df to agregate misclassifications from all folds\n",
    "    df_err_predictions = pd.concat([df_err_predictions, err], axis=0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDENTIFY MISCLCASSIFIED PATIENTS IN THE ORIGIN `BL` TABLE AND LINK BOTH TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = df_err_predictions.loc[df_err_predictions.fold_nr_ == 0].index\n",
    "bl_miss = bl_train_all_copy.loc[df_err_predictions.index]\n",
    "\n",
    "cols = ['y_true_', 'y_pred_', 'KFolds_nr_', 'Fold_nr_', 'Usage2_']\n",
    "df_err_predictions = df_err_predictions[cols]\n",
    "bl_miss = bl_miss.merge(df_err_predictions, how='left', left_index=True, right_index=True, indicator='MERGE_misclassification_k10_')\n",
    "print(bl_miss.shape)\n",
    "display(df_err_predictions.head())\n",
    "minfo.iterate_patient_GUI(df_err_predictions, column='Fold_nr_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVE MISCLASSIFICATIONS TO THE FILE (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = 1\n",
    "\n",
    "if save:     \n",
    "    filename = file_name_prefix + '_bl_missclassified.csv'\n",
    "    bl_misclassified_name = RESULTS_DIR / filename\n",
    "    bl_miss.sort_values(by=['RID'], inplace=True)    \n",
    "    bl_miss.to_csv(bl_misclassified_name, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE IMPORTANCE (OUT OF 10 FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance_all.reset_index(inplace=True)\n",
    "feat_importance_all = feat_importance_all.rename({'index': 'feature'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(feat_importance_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance_all_stats = pd.DataFrame.from_dict({'feature':feat_importance_all.feature, 'mean':feat_importance_all.mean(axis=1).round(2), 'std.':feat_importance_all.std(axis=1).round(2)})\n",
    "feat_importance_all_stats.sort_values(by='mean',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer 2D df to 1D df (melt)\n",
    "#https://stackoverflow.com/questions/40877135/plotting-two-columns-of-dataframe-in-seaborn\n",
    "# label text size\n",
    "#https://stackoverflow.com/questions/12444716/how-do-i-set-the-figure-title-and-axes-labels-font-size-in-matplotlib\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "fig.suptitle('Feature Importance - mean for k=10 folds', fontsize=26,fontweight='bold')\n",
    "ax.set_xlabel('xlabel', fontsize=24)\n",
    "ax.set_ylabel('ylabel', fontsize=24) \n",
    "ax.tick_params(labelsize=14)\n",
    "\n",
    "tidy = feat_importance_all.melt(id_vars='feature').rename(columns=str.title)\n",
    "tidy = tidy.sort_values(by=['Value'], ascending=False)\n",
    "sns.barplot(y='Feature', x='Value', ci='sd', capsize=.2, data=tidy, ax=ax, orient=\"h\")\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Relative Importance', fontsize=24)\n",
    "plt.ylabel('',fontsize=24)\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "file_name_prefix_ext = f'{file_name_prefix}-TRAIN-feat-importance-horiz.png'\n",
    "file_name_prefix_path = RESULTS_DIR / file_name_prefix_ext\n",
    "plt.savefig(file_name_prefix_path)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (For vertical plotting of  feature importance plot) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(30, 10))\n",
    "fig.suptitle('Mean feature importance for k=10 folds', fontsize=26,fontweight='bold')\n",
    "ax.set_xlabel('xlabel', fontsize=24)\n",
    "ax.set_ylabel('ylabel', fontsize=24) \n",
    "ax.tick_params(labelsize=14)\n",
    "\n",
    "#tidy = feat_importance_all.melt(id_vars='feature').rename(columns=str.title)\n",
    "#tidy = tidy.sort_values(by=['Value'], ascending=False)\n",
    "sns.barplot(x='Feature', y='Value', ci='sd', capsize=.2, data=tidy, ax=ax)\n",
    "#sns.despine(fig)\n",
    "\n",
    "file_name_prefix_ext = f'{file_name_prefix}-TRAIN-feat-importance-vert.png'\n",
    "file_name_prefix_path = RESULTS_DIR / file_name_prefix_ext\n",
    "plt.savefig(file_name_prefix_path)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(score)\n",
    "score_stats = pd.DataFrame.from_dict({'mean':score.mean(axis=1).round(3), 'std.':score.std(axis=1).round(4)})\n",
    "display(score_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validation_test_length)\n",
    "print(validation_test_length.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of confusion matix over k=10 folds\n",
    "conf_mat_mean = conf_matrix_all.mean(axis=0)\n",
    "# percantage values of confusion matix according to validatin set lenght\n",
    "conf_mat_mean_prc = conf_mat_mean / validation_test_length.mean() * 100\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.set_aspect(aspect=1)\n",
    "lab = ['sMCI', 'cAD']\n",
    "res = sns.heatmap(conf_mat_mean, annot=True, xticklabels=lab, yticklabels=lab, ax=ax,annot_kws={\"fontsize\":20}, fmt='.1f')\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "_ = ax.set_title('Confusion matrix - cross validation', size=24, fontweight='bold')\n",
    "\n",
    "\n",
    "for t,p in zip(res.texts, conf_mat_mean_prc.flat):\n",
    "    p = np.asarray(np.round(p,0), int)\n",
    "    t.set_text(t.get_text() + f' ({p}%)')\n",
    "    \n",
    "file_name_prefix_ext = f'{file_name_prefix}-TRAIN-conf-matrix.png'\n",
    "file_name_prefix_path = RESULTS_DIR / file_name_prefix_ext\n",
    "plt.savefig(file_name_prefix_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZATION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/how-to-visualize-a-decision-tree-from-a-random-forest-in-python-using-scikit-learn-38ad2d75f21c\n",
    "# Extract single tree\n",
    "#estimator = clf.estimators_[4]\n",
    "\n",
    "#from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "#export_graphviz(estimator, out_file='tree.dot', \n",
    "#                feature_names = X_train_scaled.columns,\n",
    "#               class_names = ['sMCi','cAD'],\n",
    "#                rounded = True, proportion = False, \n",
    "#                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "#from subprocess import call\n",
    "#filename1 = file_name_prefix + '.png'\n",
    "#filename2 = file_name_prefix + '.pdf'\n",
    "\n",
    "#filepath1 = RESULTS_DIR/filename1\n",
    "#filepath2 = RESULTS_DIR/filename2\n",
    "\n",
    "#call(['dot', '-Tpng', 'tree.dot', '-o', filepath1, '-Gdpi=300'])\n",
    "#call(['dot', '-Tpdf', 'tree.dot', '-o', filepath2, '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "#from IPython.display import Image\n",
    "#Image(filename = filepath1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REMOVE TEMPORARY `tree.png` and `tree.dot` FILES FROM THE CURRENT FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if 1:\n",
    "#    [f.unlink() for f in list(Path('.').glob(\"tree.*\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test_scaled)\n",
    "metrics.accuracy_score(y_test_b, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_test_pred = clf.predict(X_test_scaled).reshape(-1,)\n",
    "\n",
    "# metrics\n",
    "f1 = metrics.f1_score(y_test_b, y_test_pred)\n",
    "acc = metrics.accuracy_score(y_test_b, y_test_pred)\n",
    "recall = metrics.recall_score(y_test_b, y_test_pred)\n",
    "prec = metrics.precision_score(y_test_b, y_test_pred)\n",
    "\n",
    "print(f'F1: {f1:.3f}')\n",
    "print(f'ACC: {acc:.3f}')\n",
    "print(f'RECALL: {recall:.3f}')\n",
    "print(f'PREC: {prec:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_test  = metrics.confusion_matrix(y_test_b, y_test_pred)    \n",
    "print(conf_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of confusion matix over k=10 folds\n",
    "conf_mat_mean = conf_matrix_all.mean(axis=0)\n",
    "# percantage values of confusion matix according to validatin set lenght\n",
    "conf_matrix_test_prc = conf_matrix_test / y_test.shape[0] * 100\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.set_aspect(aspect=1)\n",
    "lab = ['sMCI', 'cAD']\n",
    "res = sns.heatmap(conf_matrix_test, annot=True, xticklabels=lab, yticklabels=lab, ax=ax,annot_kws={\"fontsize\":20}, fmt='.1f')\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "_ = ax.set_title('Confusion matrix - test', size=24, fontweight='bold')\n",
    "\n",
    "\n",
    "for t,p in zip(res.texts, conf_matrix_test_prc.flat):\n",
    "    p = np.asarray(np.round(p,0), int)\n",
    "    t.set_text(t.get_text() + f' ({p}%)')\n",
    "    \n",
    "file_name_prefix_ext = f'{file_name_prefix}-TEST-conf-matrix.png'\n",
    "file_name_prefix_path = RESULTS_DIR / file_name_prefix_ext\n",
    "plt.savefig(file_name_prefix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(clf.feature_importances_,index=X_train_scaled.columns).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index, ci='sd')\n",
    "\n",
    "fig.suptitle('Features Importance test set', fontsize=26,fontweight='bold')\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Relative Importance', fontsize=24)\n",
    "plt.ylabel('',fontsize=24)\n",
    "plt.title(\"Features Importance for test set\", fontsize=24, fontweight='bold', pad=20)\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.grid()\n",
    "\n",
    "file_name_prefix_ext = f'{file_name_prefix}-TEST-feat-importance-horiz.png'\n",
    "file_name_prefix_path = RESULTS_DIR / file_name_prefix_ext\n",
    "plt.savefig(file_name_prefix_path)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE PERMUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = PermutationImportance(clf, random_state=42).fit(X_test_scaled, y_test_b)\n",
    "X_test.head()\n",
    "eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial dependece plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "print(X_test_df.shape)\n",
    "display(X_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "print(X_test_scaled_df.shape)\n",
    "display(X_test_scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import pdp\n",
    "if 'Subgroup_' in features: features.remove('Subgroup_')\n",
    "for feature in X_test.columns:\n",
    "    pdp_goals = pdp.pdp_isolate(model=clf, dataset=X_test_scaled_df, model_features=X_test.columns.tolist(), feature=feature)\n",
    "    pdp.pdp_plot(pdp_goals, feature)\n",
    "\n",
    "    file_name_prefix_ext = f'{file_name_prefix}-pdp-TEST-{feature}.png'\n",
    "    file_name_prefix_path = RESULTS_DIR / file_name_prefix_ext\n",
    "    plt.savefig(file_name_prefix_path)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mci",
   "language": "python",
   "name": "mci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
